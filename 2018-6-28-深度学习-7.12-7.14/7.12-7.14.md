# 7.12 Dropout

**本节主要内容：**

1. **Dropout原理**

2. **Dropout性能介绍和分析**

3. **Dropout优缺点**

   

Dropout可以被认为是集成大量深层网络神经的实用Bagging方法。Dropout提供了一种廉价的Bagging集成近似，能够训练和评估指数级数量的神经网络。

**Bagging缺点：**Bagging训练多个模型，并在每个测试样本上评估多个模型。当每个模型都是一个很大的神经网络时，这种训练和评估需要花费很多运行时间和内存，不切实际。

Dropout训练的集成包括所有从基础网络除去**非输出单元**后形成的子网络，每个子网络中遇到的训练集是**有放回**采样的原始训练集的一个子集。如下图所示。我们只需将一些单元的输出**乘零**就能有效地删除一个单元。

![image][1]

**Dropout原理**: 

1. Dropout将基础网络划分为多个子网络，其中子网络为把所有从基础网络除去**非输出单元**后形成的子网络；

2. 将输入通过修改后的子网络进行前向传播，然后将误差通过修改后的子网络进行反向传播；

3. 对于另外一批待训练的子网络，重复上述操作。

   **具体来说**，在训练中使用Dropout时，我们会使用基于小批量产生较小步长的学习算法，如随机梯度下降的等。我们每次在小批量中加载一个样本，然后随机抽样应用于网络中所有输入和隐藏单元的不同**二值掩码**。对于每个单元，掩码是**独立采样**的。掩码值为**1**的采样概率（导致包括一个单元）是训练开始前一个固定的超参数。通常在每一个小批量训练的神经网络中，一个输入单元被包括的概率为0.8，一个隐藏单元被包括的概率为0.5。然后，我们运行和之前一样的前向传播、反向传播以及学习更新。

   **更正式地说**，假设一个掩码向量 $\alpha$ 指定被包括的单元，$J(\Theta,\mu)$ 是由参数$\Theta$和掩码 $\mu$定义的模型代价。那么Dropout训练的目标是最小化$E_\mu J(\Theta,\mu)$。这个期望包含多达指数级的项，但我们可以通过抽样$\mu$获得梯度的无偏估计。

   **无偏估计**：估计量的数学期望等于被估计参数的真实值，则称此估计量为被估计参数的无偏估计。

   Dropout的前向传播如下图所示：

   ![image][2]

   **Dropout训练与Bagging训练的区别**：

   1. 在Bagging情况下，所有的模型都是**独立**的。在Dropout的情况下，所有模型**共享参数**，其中每个模型继承父神经网络参数的不同子集。
   2. 在Bagging情况下，每一个模型在其相应训练集上训练到收敛。在Dropout情况下，通常大部分模型都没有显示地被训练，因为通常父神经网络会很大，不可能采集完所有的子网络。取而代之的是，在单个步骤中我们训练一小部分的子网络，**参数共享**会使得剩余的子网络也能有好的参数设定。
   3. 除了这些，Dropout与Bagging算法一样。

   Bagging集成必须根据所有成员的累积投票做一个预测，在这种背景下，我们将这个过程称为**推断**。现在，我们假定该模型的作用是**输出一个概率分布**。在Bagging情况下，每个模型$i$产生一个概率分布$p^(i)(y|x)$。集成的预测由这些分布的算术平均值给出：

   ​                                                                  $$ \frac{1}{k}\sum_{i=1}^{k}p^(i)(y|x) $$

   在Dropout情况下，通过掩码$\mu$定义每个子模型的概率分布$p(y|x,\mu)$。所有掩码的算术平均值由下式给出：

   ​                                                                   $$\sum_\mu p(\mu)p(y|x,\mu)$$

   其中，$p(\mu)$是训练时采样$\mu$的概率分布。

   因为这个求和包含多达指数级的项，除非模型的结构允许某种形式的简化，否则是不可能计算的。一个好的方法能不错地近似整个集成的预测，且只需一个前向传播的代价。这个方法就是改用集成成员预测分布的**几何平均**而不是**算术平均**。通过几何平均直接定义的非标准化概率分布由下式给出：

   ​                                                              $$\tilde{p}_{ensemble}(y|x)=\sqrt[2^d]{\prod_{\mu}p(y|x,\mu)}$$

   ​	其中d是可被丢弃的单元数。为了简化介绍，我们使用均匀分布的$\mu$。为了做出预测，我们必须重新标准化集成：

   ​                                                             $$p_{ensemble}(y|x)=\frac{\tilde p_{ensemble}(y|x) }{\sum_{y'}\tilde p_{ensemble}(y'|x)}$$

   ​	涉及Dropout的一个**重要观点**：我们可以通过评估模型中$p(y|x)$来近似$p_{ensemble}$：该模型具有**所有单元**，但我们将**单元$i$的输出的权重乘以单元$i$的被包含概率**。这个修改的**动机**是得到从该单元输出的正确期望值。我们把这种方法称为**权重比例推断规则**。

   ​	权重比例推断规则的目标是确保在**测试**时一个单元的期望总输入与在**训练**时该单元的期望总输入是大致相同的。

   ​	对许多**不具有非线性隐藏单元**的模型族而言，权重比例推断规则是精确的。

   ​	权重比例推断规则在其他设定下也是精确的，包括**条件正态输出的回归网络以及那些隐藏层不包含非线性的深度网络**。然而，权重比例推断规则对具有非线性的深度模型仅仅是一个近似。这个近似在实践中往往效果很好。

   **Dropout优点**：

   1. Dropout比其他标准的计算开销小的正则化方法（如权重衰减、过滤器范数约束和稀疏激活的正则化）更有效。Dropout也可以与其他形式的正则化合并，得到进一步的提升。
   2. 计算方便。
   3. 不怎么限制适用的模型或训练过程。几乎在所有使用分布式表示且可以用随机梯度下降训练的模型上都表现很好。

   **Dropout的缺点**：

   1. 虽然Dropout在特定模型上每一步的代价是微不足道的，但在**一个完整的系统上**使用Dropout的代价可能**非常显著**。对于非常大的数据集，正则化带来的泛化误差减少得很小。在这些情况下，使用Dropout和更大模型的计算代价可能超过正则化带来的好处。

   2. 只有极少数的训练样本可用时，Dropout不会很有效。

   对于深度模型而言，Dropout与权重衰减是**不等同**的。Dropout作用于线性回归时，相当于每个输入特征具有**不同权重衰减系数**的L2权重衰减。每个特征的权重衰减系数的大小是由其方差来确定的。

   使用Dropout训练时的随机性不是这个方法成功的必要条件，它仅仅是近似所有子模型总和的一个方法。

   **快速Dropout**：减小梯度计算中的随机性而获得更快的收敛速度。快速Dropout在小神经网络上的性能几乎与标准的Dropout相当，但是在大问题上尚未产生显著改善。

   随机性对实现Dropout的正则化效果**不是必要的，同时也不是充分的**。只有当随机抽样的集成成员相互独立地训练好后，才能达到Bagging集成的正则化效果。？？？

   Dropout启发其他以随机方法训练指数量级的共享权重的集成。

   一种关于Dropout的重要见解是，通过随机行为训练网络并**平均多个随机决定**进行预测，实现了一种**参数共享**的Bagging形式。

   目前为止，我们将Dropout介绍为一种纯粹高效近似Bagging的方法。然而，更进一步的观点，Dropout不仅仅是训练一个Bagging的集成模型，而且是**共享隐藏单元**的集成模型。这意味着无论其他隐藏单元是否在模型中，每个隐藏单元必须都能够表现良好。

   Dropout强大的大部分原因来自**施加到隐藏单元的掩码噪声**。这可以看做对输入内容的信息高度智能化、自适应破坏的一种形式，而**不是对输入原始值**的破坏。

   Dropout的另一个重要方面是噪声是**乘性**的。

   另一种深度学习算法——**批标准化**，在训练时向隐藏单元引入加性和乘性噪声重新参数化模型。批标准化的主要目的是改善优化，但噪声具有正则化的效果，有时没必要再使用Dropout。

   

# 7.13 对抗训练

   **本节主要内容：**

   1. **对抗训练的定义**

   2. **对抗训练的作用**

   ![image][3]

    通过添加噪声，在原样本基础上进行变换，得到的样本发生了微妙的变化，将“panda”错判成 “gibbon”(长臂猿)。这个和数据增强不同，图中添加噪声的方式是在梯度方向上做了一点非常小的变化，导致模型就无法正确的分类，这样生成的样本也就是**对抗样本**。

   **对抗训练**：在对抗扰动的训练集样本上训练网络，可以减少原有独立同分布的测试集的错误率。

​    对抗训练通过鼓励网络在训练数据附近的局域区域恒定来**限制**这一高度敏感的**局部线性行为**。这可以看做一种明确地向监督神经网络引入局部恒定先验的方法。

   对抗训练有助于体现**积极正则化与大型函数族结合**的力量。

   对抗样本也提供了一种实现**半监督学习**的方法，具体做法为：1. 在与数据集中的标签不相关联的点$x$处，模型本身为其分配一些标签 $\hat{y}$，该标签不一定是真正的标签值。2. 搜索一个对抗样本$x'$,导致分类器输出一个标签$y'$且$y'\not=\hat y$。这种不使用真正的标签，而是由**训练好的模型**提供标签产生的对抗样本被称为**虚拟对抗样本**。3.训练分类器为$x和x'$分配相同的标签。

   

# 7.14 切面距离、正切传播和流形正切分类器

   **本节主要内容：**

   1. **切面距离**
   2. **正切传播**
   3. **流形正切分类器**

   

   **切面距离**算法：是一种非参数的最近邻算法，其中使用的度量不是通用的欧几里得距离，而是根据邻近流形关于聚集概率的知识导出的。采样的度量方式是：将点$x_1和x_2$各自所在的流形$M_1和M_2$的距离作为点$x_1和x_2$之间的最近邻距离。然而这可能在计算上是困难的，一种局部合理的廉价代替是使用$x_i$点处切平面近似$M_i$，并测量两条切平面或一个切平面和点之间的距离。

   **正切传播**算法：训练带有额外惩罚的神经网络分类器，使**神经网络的每个输出$f(x)$对已知的变化因素是局部不变的**。这些变化因素对应于沿着相同样本聚集的流形的移动。这里实现局部不变性的方法是要求$\nabla_xf(x)$与已知流形的切向$v^(i)$正交，或者等价地通过正则化惩罚$\Omega$**使$f在x的v^(i)$方向的导数较小**：

   ​						              	$$\Omega(f)=\sum_i((\nabla_xf(x)^Tv^(i)))^2$$

   

   正切传播与**数据集增强**密切相关。两者相同点：用户通过指定一组应当**不会改变网络输出**的转换，将其先验知识编码至算法中。不同点：数据集增强的情况下，网络**显式地**训练正确分类这些施加大量变换后产生的不同输入。正切传播不需要显式访问一个新的输入点，取而代之，它解析地对模型正则化从而在指定转换的方向抵抗扰动。这种方法有一定的**缺点**：1. 模型的正则化只能抵抗无穷小的扰动。显式的数据集增强能抵抗较大的扰动。2. 我们很难在基于整流线性单元的模型上使用无限小的方法。

   正切传播、双反向传播？？、对抗训练的关系：数据集增强是正切传播非无限小的版本，对抗训练是双反向传播非无限小的版本。

   流形正切分类器：使用自编码器通过无监督学习来**学习流形的结构**，以及如正切传播一样使用这些切面正则化神经网络分类器。

[1]: image/1.png
[2]: image/2.png

[3]:image/3.png



