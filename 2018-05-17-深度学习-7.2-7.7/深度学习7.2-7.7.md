# 深度学习7.2~7.7

---



## 7.2 作为约束的范数惩罚

**本节主要内容：**

1. **$\alpha$大小与范数正则化之间的关系。**

2. **重投影方法。**

   

对于经过参数范数正则化的代价函数：

![image][1]

构造一个广义Lagrange函数：

![image][2]

这里相当于原优化$J(\theta;X,y)$增加了约束$\Omega(\theta) - k \leq 0$，所以这里标题叫**作为约束的范数惩罚**。

这个约束问题的解由下式给出：

![image][3]

注意到在这个问题里面，$\theta$和$\alpha$都是可变的，为求得最优值，它两都需要调整。这里的**惩罚项**“$\alpha(\Omega(\theta - k))$”中的$\alpha$就叫做**KKT乘子**，有它在就相当于约束$\Omega(\theta) - k \leq 0$ （互补松弛性质）。**最优值$\alpha^*$也鼓励$\Omega(\theta)$收缩，但不会强到使得$\Omega(\theta)$小于k？？？**

固定$\alpha^*$，问题变成只跟$\theta$相关的函数：

![image][4]

这就变成了和最小化$\widetilde{J}$的正则化训练问题完全一样的问题。

也就是说**参数范数惩罚**可以看作**对权重强加的约束**。例如$\Omega$是$L^2$范数，那么权重就被约束在一个$L^2$球中。$\Omega$是$L^1$范数，那么权重就是被约束在一个$L^1$范数限制的区域中（方体？）。

这里不能直接得到**k**，所以我们不知道约束区域的确切大小，但是它们有这样的对应关系**较大的$\alpha$将得到一个较小的约束区域，较小的$\alpha$将的到一个较大的约束区域。**



使用上述的**参数范数惩罚**会产生问题：

- 导致目标函数非凸而使算法陷入局部极小（对应于小的$\theta$）。这在训练神经网络时，通常表现为训练带有几个“死亡单元”的神经网络，因为它们的出入权重很小。

所以有时候我们希望使用显式的限制，而不是惩罚。如第4.4节，可以修改下降算法（如随机梯度下降算法），使其先计算$J(\theta)$的下降步，然后将$\theta$投影到满足$\Omega(\theta)<k$的最近点。（**重投影**）

这里搬出4.4节中的原话，**约束优化的一个简单方法是将约束考虑在内后简单地对梯度下降进行修改。**只能在步长为$\epsilon$范围内搜索可行的新$x$点。

**重投影**实现的显式约束不鼓励权重接近原点，通过重投影实现额显式约束只在权重变大并试图离开限制区域时产生作用。

- 重投影的显式约束可以防止权重无限制的增加。
- 不会改变目标函数的凸性，而使算法陷入局部极小。



Hinton建议使用约束和高学习速率，这样能更快地探索参数空间，并保持一定稳定性。另外还推荐**约束神经网络层的权重矩阵每列的范数，而不是限制整个权重矩阵的Frobenius范数**，这样可以防止某一隐藏单元有非常大的权重。



---



## 7.3 正则化和欠约束问题

**本节主要内容：**

1. **正则化可以解决欠定问题中矩阵不可逆的问题。**（所以标题是不是有问题？？？）

   

机器学习中许多线性模型，包括线性回归和PCA，都依赖于对矩阵$X^TX$求逆，只要$X^TX$是**奇异的**，这些方法就会失效。这种情况下，正则化的许多形式对应求逆$X^TX+\alpha I$，这个正则化矩阵可以**保证**是可逆的。

（矩阵行列式不为零，则为可逆矩阵。矩阵的行列式等于它特征值的乘积。）



相关矩阵可逆时，这些线性问题有闭式解。没有闭式解的问题也可能是**欠定的**。

（**欠定方程组：**对于方程组$Ra=y$，R为$n\times m$矩阵，且$n<m$，则方程组有无穷多组解。）

对于欠定的问题，例如线性可分问题的逻辑回归，如果权重向量$w$可以实现完美分类，那么$2w$也会以更高似然实现完美分类，类似梯度下降的迭代优化算法将持续增加$w$的大小，最终导致数值溢出。

![image][5]

![image][6]

(观察上面逻辑回归的式子，在可以完美分类的情况下，如果没有正则化项，为了趋近0或1，$\theta^T x$的绝对值会越来越大)

使用正则化之后，将约束$w$的大小，**大多数形式的正则化能够保证应用于欠定问题的迭代方法收敛。**



对于Moore-Penrose求解伪逆：

![image][7]

就像使用极小的正则化来稳定欠定问题。



---



## 7.4 数据集增强

**本节主要内容：**

1， **数据增强的方法以及需要注意的问题。**



让机器学习模型泛化得更好的**最好**办法是使用更多的数据进行训练。由于实际中数据有限，解决这个问题的一种方法是创建**假数据**并添加到训练集中。

有时候生成假数据很简单，例如分类问题，有时候又很难，比如**密度估计任务。**

我们必须要小心，不能使用会改变类别的转换。例如，光学字符识别任务需要认识到`b`和`d`以及`6`和`9`的区别，镜像翻转或者180度旋转在这里会有问题。



在神经网络的**输入层**注入噪声也可以看作数据增强的一种方式，向隐藏神经元施加噪声也是可行的，这可以看作在多个抽象层上进行的数据集增强。正则化策略**Dropout**可以看作通过与噪声相乘构建新输入的过程。



在比较不同机器学习模型的性能时，要注意数据增强带来的差异。



----



## 7.5 噪声鲁棒性



第7.4节已经提出将噪声作用于输入，作为数据集增强策略。对于某些模型而言，向输入添加**方差极小**的噪声等价于对权重施加**范数惩罚**。



另一种正则化模型的噪声使用方式是将其加到权重。在某些假设下，施加于权重的噪声可以被解释为与更传统的正则化形式等同，鼓励要学习函数保持稳定。

（省略部分证明，暂时看不明白）

这种形式的正则化鼓励参数进入权重扰动对输出相对影响较小的参数空间区域。换句话说，它推动模型进入对权重小的变化相对不敏感的区域，找到的点不只是**极小点**，还是**由平坦区所包围的极小点**。



### 7.5.1 向输出目标注入噪声



向输出目标注入噪声的原因：

- 大多数数据集的$y$标签都有一定错误。错误的$y$不利于最大化$\log p(y|x)$。可以对这噪声进行建模，就相当于注入噪声。
- 使用softmax函数和明确目标的最大似然函数可能永远不会收敛——softmax函数永远无法真正预测0概率或1概率，因此它会继续学习越来越大的权重，使预测更极端（例如7.3中的逻辑回归）。

所有我们可以假设，对于一些小常数$\epsilon$，训练集标记$y$使正确的概率是$1-\epsilon$，（以$\epsilon$的概率）任何其他可能的标签也可能是正确的。例如，**标签平滑**通过把确切分类目标从0和1替换成$\frac{\epsilon}{k-1}$和$1-\epsilon$。

标签平滑能够防止模型追求确切概率而不影响模型学习正确分类。



---



## 7.6 半监督学习



在半监督学习的框架下，$P(x)$产生的未标记样本和$P(x,y)$中的标记样本都用于估计$P(y|x)$或者根据x预测y。

在深度学习背景下，半监督学习通常指的是学习一个表示$h=f(x)$，学习表示的目的是使相同类中的样本有类似的表示。

（本节知识应该参考西瓜书中的半监督学习）





----

## 7.7 多任务学习



多任务学习是通过合并几个任务中的样例来提高泛化的一种方式。

![image][8]

因为共享参数，其统计强度可大大提高（共享参数的样本数量相对于单任务模式增加的比例），并能改善泛化和泛化误差的范围。**当然，仅当不同的任务之间存在某些统计关系的假设是合理时才会发生这种情况。**



(还有一种叫做多目标学习。多目标：类别之间是独立的，不要求互斥偶 ，多分类： 类别之间是互斥的 )





---

[1]: images/1.png
[2]: images/2.png
[3]: images/3.png
[4]: images/4.png
[5]: images/5.png
[6]: images/6.png
[7]: images/7.png
[8]: images/8.png

